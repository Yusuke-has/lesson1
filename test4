


import requests
from bs4 import BeautifulSoup
import pandas as pd

from time import sleep



d_list=[]

base_url="https://next.rikunabi.com/rnc/docs/cp_s00700.jsp?jb_type_long_cd=0100000000&wrk_plc_long_cd=0313000000&wrk_plc_long_cd=0313100000&wrk_plc_long_cd=0314000000&curnum={}"
for i in range(3):
       
    url=base_url.format(1+50*i)
    sleep(3)
    r=requests.get(url,timeout=3)
    r.raise_for_status()

    soup=BeautifulSoup(r.content,"lxml")

    companies=soup.select("a:-soup-contains(企業ページ)")

    for company_access in companies:
        company_access="https://next.rikunabi.com/"+company_access.get("href")

        sleep(5)

        company_r=requests.get(company_access)
        company_r.raise_for_status()
        table=BeautifulSoup(company_r.content,"lxml")

        company_name=table.select_one(".rnn-breadcrumb>li:last-of-type").text

    
        company_url=table.select_one(".rnn-linkText").get("href")

        d_list.append({"company_name":company_name,
                    "company_url": company_url
                    })

        
        print(d_list)



df=pd.DataFrame(d_list)
df.to_csv("company_list2-2.csv",index=None,encoding="utf-8-sig")   
    
